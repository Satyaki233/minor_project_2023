{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_entropy import *\n",
    "\n",
    "target,features = get_entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['s1', 's1', 's1', 's1', 's1', 's1', 's1', 's1', 's1', 's1', 's10',\n",
       "        's10', 's10', 's10', 's10', 's10', 's10', 's10', 's10', 's10',\n",
       "        's11', 's11', 's11', 's11', 's11', 's11', 's11', 's11', 's11',\n",
       "        's11', 's12', 's12', 's12', 's12', 's12', 's12', 's12', 's12',\n",
       "        's12', 's12', 's13', 's13', 's13', 's13', 's13', 's13', 's13',\n",
       "        's13', 's13', 's13', 's14', 's14', 's14', 's14', 's14', 's14',\n",
       "        's14', 's14', 's14', 's14', 's15', 's15', 's15', 's15', 's15',\n",
       "        's15', 's15', 's15', 's15', 's15', 's16', 's16', 's16', 's16',\n",
       "        's16', 's16', 's16', 's16', 's16', 's16', 's17', 's17', 's17',\n",
       "        's17', 's17', 's17', 's17', 's17', 's17', 's17', 's18', 's18',\n",
       "        's18', 's18', 's18', 's18', 's18', 's18', 's18', 's18', 's19',\n",
       "        's19', 's19', 's19', 's19', 's19', 's19', 's19', 's19', 's19',\n",
       "        's2', 's2', 's2', 's2', 's2', 's2', 's2', 's2', 's2', 's2', 's20',\n",
       "        's20', 's20', 's20', 's20', 's20', 's20', 's20', 's20', 's20',\n",
       "        's21', 's21', 's21', 's21', 's21', 's21', 's21', 's21', 's21',\n",
       "        's21', 's22', 's22', 's22', 's22', 's22', 's22', 's22', 's22',\n",
       "        's22', 's22', 's23', 's23', 's23', 's23', 's23', 's23', 's23',\n",
       "        's23', 's23', 's23', 's24', 's24', 's24', 's24', 's24', 's24',\n",
       "        's24', 's24', 's24', 's24', 's25', 's25', 's25', 's25', 's25',\n",
       "        's25', 's25', 's25', 's25', 's25', 's26', 's26', 's26', 's26',\n",
       "        's26', 's26', 's26', 's26', 's26', 's26', 's27', 's27', 's27',\n",
       "        's27', 's27', 's27', 's27', 's27', 's27', 's27', 's28', 's28',\n",
       "        's28', 's28', 's28', 's28', 's28', 's28', 's28', 's28', 's29',\n",
       "        's29', 's29', 's29', 's29', 's29', 's29', 's29', 's29', 's29',\n",
       "        's3', 's3', 's3', 's3', 's3', 's3', 's3', 's3', 's3', 's3', 's30',\n",
       "        's30', 's30', 's30', 's30', 's30', 's30', 's30', 's30', 's30',\n",
       "        's31', 's31', 's31', 's31', 's31', 's31', 's31', 's31', 's31',\n",
       "        's31', 's32', 's32', 's32', 's32', 's32', 's32', 's32', 's32',\n",
       "        's32', 's32', 's33', 's33', 's33', 's33', 's33', 's33', 's33',\n",
       "        's33', 's33', 's33', 's35', 's35', 's35', 's35', 's35', 's35',\n",
       "        's35', 's35', 's35', 's35', 's36', 's36', 's36', 's36', 's36',\n",
       "        's36', 's36', 's36', 's36', 's36', 's37', 's37', 's37', 's37',\n",
       "        's37', 's37', 's37', 's37', 's37', 's37', 's38', 's38', 's38',\n",
       "        's38', 's38', 's38', 's38', 's38', 's38', 's38', 's39', 's39',\n",
       "        's39', 's39', 's39', 's39', 's39', 's39', 's39', 's39', 's4', 's4',\n",
       "        's4', 's4', 's4', 's4', 's4', 's4', 's4', 's4', 's40', 's40',\n",
       "        's40', 's40', 's40', 's40', 's40', 's40', 's40', 's40', 's5', 's5',\n",
       "        's5', 's5', 's5', 's5', 's5', 's5', 's5', 's5', 's6', 's6', 's6',\n",
       "        's6', 's6', 's6', 's6', 's6', 's6', 's6', 's7', 's7', 's7', 's7',\n",
       "        's7', 's7', 's7', 's7', 's7', 's7', 's8', 's8', 's8', 's8', 's8',\n",
       "        's8', 's8', 's8', 's8', 's8', 's9', 's9', 's9', 's9', 's9', 's9',\n",
       "        's9', 's9', 's9', 's9'], dtype='<U3'),\n",
       " array([[3.27326969, 3.62346519, 4.24385619, ..., 4.48385619, 3.15907957,\n",
       "         2.93469395],\n",
       "        [3.44888407, 4.05366069, 3.97366069, ..., 3.89366069, 3.47907957,\n",
       "         3.07907957],\n",
       "        [4.13366069, 3.89366069, 4.24385619, ..., 4.48385619, 3.46346519,\n",
       "         3.12721031],\n",
       "        ...,\n",
       "        [2.72321569, 2.64721031, 2.16321569, ..., 3.14346519, 3.67326969,\n",
       "         3.51326969],\n",
       "        [2.77868857, 2.33790657, 2.59248769, ..., 3.72307419, 3.27326969,\n",
       "         3.63907957],\n",
       "        [2.72229219, 2.62268319, 2.70268319, ..., 3.78346519, 3.21287869,\n",
       "         3.35326969]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X =pd.DataFrame(features)\n",
    "y = target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>386</th>\n",
       "      <th>387</th>\n",
       "      <th>388</th>\n",
       "      <th>389</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.273270</td>\n",
       "      <td>3.623465</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.293661</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.133661</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>...</td>\n",
       "      <td>3.603856</td>\n",
       "      <td>3.513270</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>3.559080</td>\n",
       "      <td>3.843856</td>\n",
       "      <td>3.639080</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>3.159080</td>\n",
       "      <td>2.934694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.448884</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>3.973661</td>\n",
       "      <td>3.699471</td>\n",
       "      <td>3.893661</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>4.133661</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>3.973661</td>\n",
       "      <td>...</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>3.783465</td>\n",
       "      <td>3.749275</td>\n",
       "      <td>4.293661</td>\n",
       "      <td>3.623465</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>3.893661</td>\n",
       "      <td>3.479080</td>\n",
       "      <td>3.079080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.133661</td>\n",
       "      <td>3.893661</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>3.189275</td>\n",
       "      <td>3.299471</td>\n",
       "      <td>3.973661</td>\n",
       "      <td>3.783465</td>\n",
       "      <td>3.893661</td>\n",
       "      <td>...</td>\n",
       "      <td>3.863465</td>\n",
       "      <td>3.413661</td>\n",
       "      <td>3.733661</td>\n",
       "      <td>3.433270</td>\n",
       "      <td>4.133661</td>\n",
       "      <td>4.373661</td>\n",
       "      <td>3.429275</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>3.463465</td>\n",
       "      <td>3.127210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.779471</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>4.373661</td>\n",
       "      <td>...</td>\n",
       "      <td>3.669275</td>\n",
       "      <td>3.349275</td>\n",
       "      <td>3.943465</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>3.208884</td>\n",
       "      <td>3.893661</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>3.413661</td>\n",
       "      <td>3.094694</td>\n",
       "      <td>2.478298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.003856</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>4.003856</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>...</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>3.513270</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>3.923856</td>\n",
       "      <td>3.833270</td>\n",
       "      <td>3.017015</td>\n",
       "      <td>3.413661</td>\n",
       "      <td>3.673270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2.713270</td>\n",
       "      <td>2.370699</td>\n",
       "      <td>2.548635</td>\n",
       "      <td>2.968884</td>\n",
       "      <td>3.459471</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>3.973661</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>3.315085</td>\n",
       "      <td>...</td>\n",
       "      <td>3.619471</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.293661</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>4.103465</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>3.703465</td>\n",
       "      <td>3.723074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2.457015</td>\n",
       "      <td>2.274444</td>\n",
       "      <td>2.798298</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>3.653661</td>\n",
       "      <td>3.589275</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>...</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.163856</td>\n",
       "      <td>4.183465</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>3.349275</td>\n",
       "      <td>3.543465</td>\n",
       "      <td>2.997406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2.723216</td>\n",
       "      <td>2.647210</td>\n",
       "      <td>2.163216</td>\n",
       "      <td>3.123216</td>\n",
       "      <td>4.103465</td>\n",
       "      <td>4.373661</td>\n",
       "      <td>4.103465</td>\n",
       "      <td>3.619471</td>\n",
       "      <td>3.943465</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>...</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.163856</td>\n",
       "      <td>4.003856</td>\n",
       "      <td>3.943465</td>\n",
       "      <td>3.833270</td>\n",
       "      <td>4.133661</td>\n",
       "      <td>3.673270</td>\n",
       "      <td>3.143465</td>\n",
       "      <td>3.673270</td>\n",
       "      <td>3.513270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2.778689</td>\n",
       "      <td>2.337907</td>\n",
       "      <td>2.592488</td>\n",
       "      <td>2.693020</td>\n",
       "      <td>2.803856</td>\n",
       "      <td>3.559080</td>\n",
       "      <td>4.133661</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.163856</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>...</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.373661</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>3.723074</td>\n",
       "      <td>3.273270</td>\n",
       "      <td>3.639080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2.722292</td>\n",
       "      <td>2.622683</td>\n",
       "      <td>2.702683</td>\n",
       "      <td>2.370699</td>\n",
       "      <td>2.740504</td>\n",
       "      <td>3.513270</td>\n",
       "      <td>4.293661</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>...</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.133661</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>3.783465</td>\n",
       "      <td>3.212879</td>\n",
       "      <td>3.353270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    3.273270  3.623465  4.243856  4.213661  4.293661  4.403856  4.133661   \n",
       "1    3.448884  4.053661  3.973661  3.699471  3.893661  4.053661  4.323856   \n",
       "2    4.133661  3.893661  4.243856  4.483856  4.053661  3.189275  3.299471   \n",
       "3    3.779471  4.213661  4.483856  4.323856  4.563856  4.563856  4.023465   \n",
       "4    4.243856  4.003856  4.403856  4.403856  4.403856  4.023465  4.403856   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "385  2.713270  2.370699  2.548635  2.968884  3.459471  4.213661  3.973661   \n",
       "386  2.457015  2.274444  2.798298  4.023465  4.053661  4.403856  3.653661   \n",
       "387  2.723216  2.647210  2.163216  3.123216  4.103465  4.373661  4.103465   \n",
       "388  2.778689  2.337907  2.592488  2.693020  2.803856  3.559080  4.133661   \n",
       "389  2.722292  2.622683  2.702683  2.370699  2.740504  3.513270  4.293661   \n",
       "\n",
       "          7         8         9    ...       386       387       388  \\\n",
       "0    4.083856  4.323856  4.213661  ...  3.603856  3.513270  4.213661   \n",
       "1    4.133661  4.323856  3.973661  ...  4.213661  4.083856  3.783465   \n",
       "2    3.973661  3.783465  3.893661  ...  3.863465  3.413661  3.733661   \n",
       "3    4.323856  4.323856  4.373661  ...  3.669275  3.349275  3.943465   \n",
       "4    4.053661  4.003856  4.023465  ...  4.023465  4.403856  4.213661   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "385  4.213661  4.053661  3.315085  ...  3.619471  4.243856  4.293661   \n",
       "386  3.589275  4.023465  4.023465  ...  4.403856  4.483856  4.023465   \n",
       "387  3.619471  3.943465  4.083856  ...  4.483856  4.163856  4.003856   \n",
       "388  4.563856  4.163856  4.483856  ...  4.483856  4.373661  4.563856   \n",
       "389  4.243856  4.213661  4.403856  ...  4.483856  4.563856  4.403856   \n",
       "\n",
       "          389       390       391       392       393       394       395  \n",
       "0    4.083856  3.559080  3.843856  3.639080  4.483856  3.159080  2.934694  \n",
       "1    3.749275  4.293661  3.623465  4.403856  3.893661  3.479080  3.079080  \n",
       "2    3.433270  4.133661  4.373661  3.429275  4.483856  3.463465  3.127210  \n",
       "3    4.403856  3.208884  3.893661  4.243856  3.413661  3.094694  2.478298  \n",
       "4    3.513270  4.213661  3.923856  3.833270  3.017015  3.413661  3.673270  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "385  4.213661  4.483856  4.053661  4.103465  4.023465  3.703465  3.723074  \n",
       "386  4.243856  4.163856  4.183465  4.083856  3.349275  3.543465  2.997406  \n",
       "387  3.943465  3.833270  4.133661  3.673270  3.143465  3.673270  3.513270  \n",
       "388  4.083856  4.243856  4.083856  4.563856  3.723074  3.273270  3.639080  \n",
       "389  4.483856  4.243856  4.133661  4.083856  3.783465  3.212879  3.353270  \n",
       "\n",
       "[390 rows x 396 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>386</th>\n",
       "      <th>387</th>\n",
       "      <th>388</th>\n",
       "      <th>389</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>390.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.860010</td>\n",
       "      <td>3.050304</td>\n",
       "      <td>3.338140</td>\n",
       "      <td>3.653419</td>\n",
       "      <td>3.914460</td>\n",
       "      <td>3.998631</td>\n",
       "      <td>3.998497</td>\n",
       "      <td>4.025775</td>\n",
       "      <td>4.037199</td>\n",
       "      <td>4.012241</td>\n",
       "      <td>...</td>\n",
       "      <td>4.096197</td>\n",
       "      <td>4.093830</td>\n",
       "      <td>4.100972</td>\n",
       "      <td>4.014990</td>\n",
       "      <td>3.893665</td>\n",
       "      <td>3.854157</td>\n",
       "      <td>3.989448</td>\n",
       "      <td>3.837700</td>\n",
       "      <td>3.614639</td>\n",
       "      <td>3.435415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.423917</td>\n",
       "      <td>0.552835</td>\n",
       "      <td>0.626397</td>\n",
       "      <td>0.579933</td>\n",
       "      <td>0.415602</td>\n",
       "      <td>0.348340</td>\n",
       "      <td>0.337031</td>\n",
       "      <td>0.337632</td>\n",
       "      <td>0.333386</td>\n",
       "      <td>0.329732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328814</td>\n",
       "      <td>0.333247</td>\n",
       "      <td>0.333327</td>\n",
       "      <td>0.348611</td>\n",
       "      <td>0.409997</td>\n",
       "      <td>0.443715</td>\n",
       "      <td>0.442160</td>\n",
       "      <td>0.559301</td>\n",
       "      <td>0.597941</td>\n",
       "      <td>0.571281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.902683</td>\n",
       "      <td>1.498455</td>\n",
       "      <td>1.991120</td>\n",
       "      <td>2.147711</td>\n",
       "      <td>2.408884</td>\n",
       "      <td>2.759080</td>\n",
       "      <td>2.394303</td>\n",
       "      <td>2.659471</td>\n",
       "      <td>2.917406</td>\n",
       "      <td>2.732879</td>\n",
       "      <td>...</td>\n",
       "      <td>2.679080</td>\n",
       "      <td>2.782683</td>\n",
       "      <td>2.668493</td>\n",
       "      <td>2.648884</td>\n",
       "      <td>2.742825</td>\n",
       "      <td>2.454694</td>\n",
       "      <td>2.538689</td>\n",
       "      <td>2.328884</td>\n",
       "      <td>2.013912</td>\n",
       "      <td>2.199080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.577907</td>\n",
       "      <td>2.647629</td>\n",
       "      <td>2.821084</td>\n",
       "      <td>3.189275</td>\n",
       "      <td>3.720078</td>\n",
       "      <td>3.847760</td>\n",
       "      <td>3.788367</td>\n",
       "      <td>3.813661</td>\n",
       "      <td>3.835916</td>\n",
       "      <td>3.843856</td>\n",
       "      <td>...</td>\n",
       "      <td>3.893661</td>\n",
       "      <td>3.915916</td>\n",
       "      <td>3.923856</td>\n",
       "      <td>3.813661</td>\n",
       "      <td>3.623465</td>\n",
       "      <td>3.515916</td>\n",
       "      <td>3.767760</td>\n",
       "      <td>3.437173</td>\n",
       "      <td>3.143465</td>\n",
       "      <td>3.014694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.822501</td>\n",
       "      <td>2.938689</td>\n",
       "      <td>3.271272</td>\n",
       "      <td>3.798563</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>4.078563</td>\n",
       "      <td>4.103465</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>...</td>\n",
       "      <td>4.163856</td>\n",
       "      <td>4.163856</td>\n",
       "      <td>4.163856</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>3.943465</td>\n",
       "      <td>3.923856</td>\n",
       "      <td>4.103465</td>\n",
       "      <td>3.943465</td>\n",
       "      <td>3.643074</td>\n",
       "      <td>3.351272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.083074</td>\n",
       "      <td>3.361210</td>\n",
       "      <td>3.943465</td>\n",
       "      <td>4.133661</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.281210</td>\n",
       "      <td>4.293661</td>\n",
       "      <td>4.293661</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>...</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>4.373661</td>\n",
       "      <td>4.293661</td>\n",
       "      <td>4.236307</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>4.293661</td>\n",
       "      <td>4.133661</td>\n",
       "      <td>3.923856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.643856</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.643856</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.643856</td>\n",
       "      <td>4.643856</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>...</td>\n",
       "      <td>4.643856</td>\n",
       "      <td>4.643856</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.643856</td>\n",
       "      <td>4.643856</td>\n",
       "      <td>4.643856</td>\n",
       "      <td>4.643856</td>\n",
       "      <td>4.643856</td>\n",
       "      <td>4.643856</td>\n",
       "      <td>4.643856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5    \\\n",
       "count  390.000000  390.000000  390.000000  390.000000  390.000000  390.000000   \n",
       "mean     2.860010    3.050304    3.338140    3.653419    3.914460    3.998631   \n",
       "std      0.423917    0.552835    0.626397    0.579933    0.415602    0.348340   \n",
       "min      1.902683    1.498455    1.991120    2.147711    2.408884    2.759080   \n",
       "25%      2.577907    2.647629    2.821084    3.189275    3.720078    3.847760   \n",
       "50%      2.822501    2.938689    3.271272    3.798563    4.023465    4.053661   \n",
       "75%      3.083074    3.361210    3.943465    4.133661    4.213661    4.243856   \n",
       "max      4.643856    4.483856    4.563856    4.563856    4.563856    4.643856   \n",
       "\n",
       "              6           7           8           9    ...         386  \\\n",
       "count  390.000000  390.000000  390.000000  390.000000  ...  390.000000   \n",
       "mean     3.998497    4.025775    4.037199    4.012241  ...    4.096197   \n",
       "std      0.337031    0.337632    0.333386    0.329732  ...    0.328814   \n",
       "min      2.394303    2.659471    2.917406    2.732879  ...    2.679080   \n",
       "25%      3.788367    3.813661    3.835916    3.843856  ...    3.893661   \n",
       "50%      4.053661    4.078563    4.103465    4.083856  ...    4.163856   \n",
       "75%      4.281210    4.293661    4.293661    4.243856  ...    4.323856   \n",
       "max      4.563856    4.643856    4.643856    4.563856  ...    4.643856   \n",
       "\n",
       "              387         388         389         390         391         392  \\\n",
       "count  390.000000  390.000000  390.000000  390.000000  390.000000  390.000000   \n",
       "mean     4.093830    4.100972    4.014990    3.893665    3.854157    3.989448   \n",
       "std      0.333247    0.333327    0.348611    0.409997    0.443715    0.442160   \n",
       "min      2.782683    2.668493    2.648884    2.742825    2.454694    2.538689   \n",
       "25%      3.915916    3.923856    3.813661    3.623465    3.515916    3.767760   \n",
       "50%      4.163856    4.163856    4.053661    3.943465    3.923856    4.103465   \n",
       "75%      4.323856    4.373661    4.293661    4.236307    4.213661    4.323856   \n",
       "max      4.643856    4.563856    4.643856    4.643856    4.643856    4.643856   \n",
       "\n",
       "              393         394         395  \n",
       "count  390.000000  390.000000  390.000000  \n",
       "mean     3.837700    3.614639    3.435415  \n",
       "std      0.559301    0.597941    0.571281  \n",
       "min      2.328884    2.013912    2.199080  \n",
       "25%      3.437173    3.143465    3.014694  \n",
       "50%      3.943465    3.643074    3.351272  \n",
       "75%      4.293661    4.133661    3.923856  \n",
       "max      4.643856    4.643856    4.643856  \n",
       "\n",
       "[8 rows x 396 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.53770706e-01,  1.52001236e+00,  2.37130072e+00, ...,\n",
       "         5.35701299e-03,  5.91679535e-04,  4.07010869e-15],\n",
       "       [ 4.85651441e-01,  2.51573672e+00, -3.16364867e-01, ...,\n",
       "        -2.21918380e-03, -5.24963351e-03,  4.07010869e-15],\n",
       "       [ 4.86008604e+00,  1.84002939e+00, -5.88657906e-01, ...,\n",
       "         2.07620519e-03,  2.34837066e-03,  4.07010869e-15],\n",
       "       ...,\n",
       "       [-4.61657370e+00,  5.60815171e-01, -2.37197564e+00, ...,\n",
       "         7.42920385e-04,  1.70504514e-04,  4.07010869e-15],\n",
       "       [-4.47973466e+00,  1.17264778e+00,  2.01961783e-03, ...,\n",
       "         9.56191056e-04,  1.71057310e-03,  4.07010869e-15],\n",
       "       [-4.91884005e+00,  3.70263194e-01, -1.82619609e+00, ...,\n",
       "        -3.46454478e-03, -5.88193959e-03,  4.07010869e-15]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_pca,y,test_size=0.25,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 390)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9081632653061225"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 2, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 4, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 3, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "con_mat = confusion_matrix(y_pred=y_pred,y_true=y_test)\n",
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591836734693877"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 3, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 4, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 3, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc.predict(X_test)\n",
    "con_mat_01 = confusion_matrix(y_pred=y_pred,y_true=y_test)\n",
    "con_mat_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>386</th>\n",
       "      <th>387</th>\n",
       "      <th>388</th>\n",
       "      <th>389</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.273270</td>\n",
       "      <td>3.623465</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.293661</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.133661</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>...</td>\n",
       "      <td>3.603856</td>\n",
       "      <td>3.513270</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>3.559080</td>\n",
       "      <td>3.843856</td>\n",
       "      <td>3.639080</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>3.159080</td>\n",
       "      <td>2.934694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.448884</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>3.973661</td>\n",
       "      <td>3.699471</td>\n",
       "      <td>3.893661</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>4.133661</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>3.973661</td>\n",
       "      <td>...</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>3.783465</td>\n",
       "      <td>3.749275</td>\n",
       "      <td>4.293661</td>\n",
       "      <td>3.623465</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>3.893661</td>\n",
       "      <td>3.479080</td>\n",
       "      <td>3.079080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.133661</td>\n",
       "      <td>3.893661</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>3.189275</td>\n",
       "      <td>3.299471</td>\n",
       "      <td>3.973661</td>\n",
       "      <td>3.783465</td>\n",
       "      <td>3.893661</td>\n",
       "      <td>...</td>\n",
       "      <td>3.863465</td>\n",
       "      <td>3.413661</td>\n",
       "      <td>3.733661</td>\n",
       "      <td>3.433270</td>\n",
       "      <td>4.133661</td>\n",
       "      <td>4.373661</td>\n",
       "      <td>3.429275</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>3.463465</td>\n",
       "      <td>3.127210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.779471</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>4.323856</td>\n",
       "      <td>4.373661</td>\n",
       "      <td>...</td>\n",
       "      <td>3.669275</td>\n",
       "      <td>3.349275</td>\n",
       "      <td>3.943465</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>3.208884</td>\n",
       "      <td>3.893661</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>3.413661</td>\n",
       "      <td>3.094694</td>\n",
       "      <td>2.478298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.003856</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>4.003856</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>...</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>3.513270</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>3.923856</td>\n",
       "      <td>3.833270</td>\n",
       "      <td>3.017015</td>\n",
       "      <td>3.413661</td>\n",
       "      <td>3.673270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2.713270</td>\n",
       "      <td>2.370699</td>\n",
       "      <td>2.548635</td>\n",
       "      <td>2.968884</td>\n",
       "      <td>3.459471</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>3.973661</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>3.315085</td>\n",
       "      <td>...</td>\n",
       "      <td>3.619471</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.293661</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>4.103465</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>3.703465</td>\n",
       "      <td>3.723074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2.457015</td>\n",
       "      <td>2.274444</td>\n",
       "      <td>2.798298</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>4.053661</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>3.653661</td>\n",
       "      <td>3.589275</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>...</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.023465</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.163856</td>\n",
       "      <td>4.183465</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>3.349275</td>\n",
       "      <td>3.543465</td>\n",
       "      <td>2.997406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2.723216</td>\n",
       "      <td>2.647210</td>\n",
       "      <td>2.163216</td>\n",
       "      <td>3.123216</td>\n",
       "      <td>4.103465</td>\n",
       "      <td>4.373661</td>\n",
       "      <td>4.103465</td>\n",
       "      <td>3.619471</td>\n",
       "      <td>3.943465</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>...</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.163856</td>\n",
       "      <td>4.003856</td>\n",
       "      <td>3.943465</td>\n",
       "      <td>3.833270</td>\n",
       "      <td>4.133661</td>\n",
       "      <td>3.673270</td>\n",
       "      <td>3.143465</td>\n",
       "      <td>3.673270</td>\n",
       "      <td>3.513270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2.778689</td>\n",
       "      <td>2.337907</td>\n",
       "      <td>2.592488</td>\n",
       "      <td>2.693020</td>\n",
       "      <td>2.803856</td>\n",
       "      <td>3.559080</td>\n",
       "      <td>4.133661</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.163856</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>...</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.373661</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>3.723074</td>\n",
       "      <td>3.273270</td>\n",
       "      <td>3.639080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2.722292</td>\n",
       "      <td>2.622683</td>\n",
       "      <td>2.702683</td>\n",
       "      <td>2.370699</td>\n",
       "      <td>2.740504</td>\n",
       "      <td>3.513270</td>\n",
       "      <td>4.293661</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.213661</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>...</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.563856</td>\n",
       "      <td>4.403856</td>\n",
       "      <td>4.483856</td>\n",
       "      <td>4.243856</td>\n",
       "      <td>4.133661</td>\n",
       "      <td>4.083856</td>\n",
       "      <td>3.783465</td>\n",
       "      <td>3.212879</td>\n",
       "      <td>3.353270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    3.273270  3.623465  4.243856  4.213661  4.293661  4.403856  4.133661   \n",
       "1    3.448884  4.053661  3.973661  3.699471  3.893661  4.053661  4.323856   \n",
       "2    4.133661  3.893661  4.243856  4.483856  4.053661  3.189275  3.299471   \n",
       "3    3.779471  4.213661  4.483856  4.323856  4.563856  4.563856  4.023465   \n",
       "4    4.243856  4.003856  4.403856  4.403856  4.403856  4.023465  4.403856   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "385  2.713270  2.370699  2.548635  2.968884  3.459471  4.213661  3.973661   \n",
       "386  2.457015  2.274444  2.798298  4.023465  4.053661  4.403856  3.653661   \n",
       "387  2.723216  2.647210  2.163216  3.123216  4.103465  4.373661  4.103465   \n",
       "388  2.778689  2.337907  2.592488  2.693020  2.803856  3.559080  4.133661   \n",
       "389  2.722292  2.622683  2.702683  2.370699  2.740504  3.513270  4.293661   \n",
       "\n",
       "          7         8         9    ...       386       387       388  \\\n",
       "0    4.083856  4.323856  4.213661  ...  3.603856  3.513270  4.213661   \n",
       "1    4.133661  4.323856  3.973661  ...  4.213661  4.083856  3.783465   \n",
       "2    3.973661  3.783465  3.893661  ...  3.863465  3.413661  3.733661   \n",
       "3    4.323856  4.323856  4.373661  ...  3.669275  3.349275  3.943465   \n",
       "4    4.053661  4.003856  4.023465  ...  4.023465  4.403856  4.213661   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "385  4.213661  4.053661  3.315085  ...  3.619471  4.243856  4.293661   \n",
       "386  3.589275  4.023465  4.023465  ...  4.403856  4.483856  4.023465   \n",
       "387  3.619471  3.943465  4.083856  ...  4.483856  4.163856  4.003856   \n",
       "388  4.563856  4.163856  4.483856  ...  4.483856  4.373661  4.563856   \n",
       "389  4.243856  4.213661  4.403856  ...  4.483856  4.563856  4.403856   \n",
       "\n",
       "          389       390       391       392       393       394       395  \n",
       "0    4.083856  3.559080  3.843856  3.639080  4.483856  3.159080  2.934694  \n",
       "1    3.749275  4.293661  3.623465  4.403856  3.893661  3.479080  3.079080  \n",
       "2    3.433270  4.133661  4.373661  3.429275  4.483856  3.463465  3.127210  \n",
       "3    4.403856  3.208884  3.893661  4.243856  3.413661  3.094694  2.478298  \n",
       "4    3.513270  4.213661  3.923856  3.833270  3.017015  3.413661  3.673270  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "385  4.213661  4.483856  4.053661  4.103465  4.023465  3.703465  3.723074  \n",
       "386  4.243856  4.163856  4.183465  4.083856  3.349275  3.543465  2.997406  \n",
       "387  3.943465  3.833270  4.133661  3.673270  3.143465  3.673270  3.513270  \n",
       "388  4.083856  4.243856  4.083856  4.563856  3.723074  3.273270  3.639080  \n",
       "389  4.483856  4.243856  4.133661  4.083856  3.783465  3.212879  3.353270  \n",
       "\n",
       "[390 rows x 396 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA \n",
    "\n",
    "lda = LDA(solver='svd')\n",
    "X_lda = lda.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.87417855,  5.04894494, -2.96675362, ..., -1.31459733,\n",
       "        -3.5494283 ,  0.6174165 ],\n",
       "       [-5.82305325,  3.54318639, -3.21798669, ..., -1.17060745,\n",
       "        -3.67287763,  1.14595489],\n",
       "       [-6.37521019,  4.5091272 , -3.50754126, ..., -2.21872007,\n",
       "        -4.49075557,  1.35267365],\n",
       "       ...,\n",
       "       [ 2.63940831, -7.78422026, -2.43169825, ..., -1.61924053,\n",
       "         3.88056747, -0.33299989],\n",
       "       [ 4.45263341, -5.3195708 , -0.77174946, ..., -2.10715119,\n",
       "         3.22848696,  0.47676874],\n",
       "       [ 3.08267457, -6.33810954, -2.92197404, ..., -1.22386689,\n",
       "         3.58658431, -0.28681921]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import  train_test_split\n",
    "\n",
    "Xl_train,Xl_test,yl_train,yl_test = train_test_split(X_lda,y,test_size=0.3,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['s1', 's1', 's1', 's1', 's1', 's1', 's1', 's1', 's1', 's1', 's10',\n",
       "       's10', 's10', 's10', 's10', 's10', 's10', 's10', 's10', 's10',\n",
       "       's11', 's11', 's11', 's11', 's11', 's11', 's11', 's11', 's11',\n",
       "       's11', 's12', 's12', 's12', 's12', 's12', 's12', 's12', 's12',\n",
       "       's12', 's12', 's13', 's13', 's13', 's13', 's13', 's13', 's13',\n",
       "       's13', 's13', 's13', 's14', 's14', 's14', 's14', 's14', 's14',\n",
       "       's14', 's14', 's14', 's14', 's15', 's15', 's15', 's15', 's15',\n",
       "       's15', 's15', 's15', 's15', 's15', 's16', 's16', 's16', 's16',\n",
       "       's16', 's16', 's16', 's16', 's16', 's16', 's17', 's17', 's17',\n",
       "       's17', 's17', 's17', 's17', 's17', 's17', 's17', 's18', 's18',\n",
       "       's18', 's18', 's18', 's18', 's18', 's18', 's18', 's18', 's19',\n",
       "       's19', 's19', 's19', 's19', 's19', 's19', 's19', 's19', 's19',\n",
       "       's2', 's2', 's2', 's2', 's2', 's2', 's2', 's2', 's2', 's2', 's20',\n",
       "       's20', 's20', 's20', 's20', 's20', 's20', 's20', 's20', 's20',\n",
       "       's21', 's21', 's21', 's21', 's21', 's21', 's21', 's21', 's21',\n",
       "       's21', 's22', 's22', 's22', 's22', 's22', 's22', 's22', 's22',\n",
       "       's22', 's22', 's23', 's23', 's23', 's23', 's23', 's23', 's23',\n",
       "       's23', 's23', 's23', 's24', 's24', 's24', 's24', 's24', 's24',\n",
       "       's24', 's24', 's24', 's24', 's25', 's25', 's25', 's25', 's25',\n",
       "       's25', 's25', 's25', 's25', 's25', 's26', 's26', 's26', 's26',\n",
       "       's26', 's26', 's26', 's26', 's26', 's26', 's27', 's27', 's27',\n",
       "       's27', 's27', 's27', 's27', 's27', 's27', 's27', 's28', 's28',\n",
       "       's28', 's28', 's28', 's28', 's28', 's28', 's28', 's28', 's29',\n",
       "       's29', 's29', 's29', 's29', 's29', 's29', 's29', 's29', 's29',\n",
       "       's3', 's3', 's3', 's3', 's3', 's3', 's3', 's3', 's3', 's3', 's30',\n",
       "       's30', 's30', 's30', 's30', 's30', 's30', 's30', 's30', 's30',\n",
       "       's31', 's31', 's31', 's31', 's31', 's31', 's31', 's31', 's31',\n",
       "       's31', 's32', 's32', 's32', 's32', 's32', 's32', 's32', 's32',\n",
       "       's32', 's32', 's33', 's33', 's33', 's33', 's33', 's33', 's33',\n",
       "       's33', 's33', 's33', 's35', 's35', 's35', 's35', 's35', 's35',\n",
       "       's35', 's35', 's35', 's35', 's36', 's36', 's36', 's36', 's36',\n",
       "       's36', 's36', 's36', 's36', 's36', 's37', 's37', 's37', 's37',\n",
       "       's37', 's37', 's37', 's37', 's37', 's37', 's38', 's38', 's38',\n",
       "       's38', 's38', 's38', 's38', 's38', 's38', 's38', 's39', 's39',\n",
       "       's39', 's39', 's39', 's39', 's39', 's39', 's39', 's39', 's4', 's4',\n",
       "       's4', 's4', 's4', 's4', 's4', 's4', 's4', 's4', 's40', 's40',\n",
       "       's40', 's40', 's40', 's40', 's40', 's40', 's40', 's40', 's5', 's5',\n",
       "       's5', 's5', 's5', 's5', 's5', 's5', 's5', 's5', 's6', 's6', 's6',\n",
       "       's6', 's6', 's6', 's6', 's6', 's6', 's6', 's7', 's7', 's7', 's7',\n",
       "       's7', 's7', 's7', 's7', 's7', 's7', 's8', 's8', 's8', 's8', 's8',\n",
       "       's8', 's8', 's8', 's8', 's8', 's9', 's9', 's9', 's9', 's9', 's9',\n",
       "       's9', 's9', 's9', 's9'], dtype='<U3')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-28 {color: black;}#sk-container-id-28 pre{padding: 0;}#sk-container-id-28 div.sk-toggleable {background-color: white;}#sk-container-id-28 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-28 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-28 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-28 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-28 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-28 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-28 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-28 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-28 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-28 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-28 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-28 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-28 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-28 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-28 div.sk-item {position: relative;z-index: 1;}#sk-container-id-28 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-28 div.sk-item::before, #sk-container-id-28 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-28 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-28 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-28 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-28 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-28 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-28 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-28 div.sk-label-container {text-align: center;}#sk-container-id-28 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-28 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-28\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" checked><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svm_2 = SVC(kernel='linear')\n",
    "svm_2.fit(Xl_train,yl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_2.score(Xl_test,yl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 3, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 5, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 3, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "yl_pred = svm_2.predict(Xl_test)\n",
    "con_mat = confusion_matrix(y_pred=yl_pred,y_true=yl_test)\n",
    "con_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((390, 38), (390,))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lda.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-29 {color: black;}#sk-container-id-29 pre{padding: 0;}#sk-container-id-29 div.sk-toggleable {background-color: white;}#sk-container-id-29 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-29 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-29 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-29 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-29 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-29 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-29 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-29 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-29 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-29 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-29 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-29 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-29 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-29 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-29 div.sk-item {position: relative;z-index: 1;}#sk-container-id-29 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-29 div.sk-item::before, #sk-container-id-29 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-29 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-29 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-29 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-29 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-29 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-29 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-29 div.sk-label-container {text-align: center;}#sk-container-id-29 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-29 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-29\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" checked><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_2 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_2.fit(Xl_train,yl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_2.score(Xl_test,yl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
